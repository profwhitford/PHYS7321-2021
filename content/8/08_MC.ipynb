{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "saving-objective",
   "metadata": {},
   "source": [
    "The Canonical Ensemble\n",
    "======================\n",
    "\n",
    "Up to this point, we have only considered constant energy systems (microcanonical ensemble). However, most physical systems are not isolated, but exchange energy with the\n",
    "environment. Since the systems are very small compared to the environment,\n",
    "we consider that the environment acts effectively as a heat reservoir or\n",
    "heat bath at a fixed temperature $T$. If a small system is put in\n",
    "thermal contact with the heat bath, it will reach thermal equilibrium\n",
    "exchanging energy until the system attains the temperature of the bath.\n",
    "\n",
    "Imagine an infinitely large number of mental copies of the system and\n",
    "the heat bath. The probability $P_s$ that the system is found in a\n",
    "microstate $s$ with energy $s$ is given by:\n",
    "$$P_s=\\frac{1}{Z}e^{-E_s/k_BT},\n",
    "$$ where $Z$ is the normalization constant. This\n",
    "corresponds to the canonical ensemble. Since $\\sum P_s = 1$, we have\n",
    "$$Z=\\sum_s{e^{-E_s/k_BT}},\n",
    "$$ where the sum is over all the possible microstates of the\n",
    "system. This equation defines the “partition function” of the system.\n",
    "\n",
    "We can use this relation to obtain the ensemble average of physical\n",
    "quantities of interest. For instance, the mean energy is given by:\n",
    "$$\\langle E \\rangle = \\sum_s E_s\\, P_s=\\frac{1}{Z}\\sum_s{E_s\\,e^{-\\beta\n",
    "E_s}},$$ with $\\beta=1/k_BT$.\n",
    "\n",
    "The Metropolis algorithm\n",
    "------------------------\n",
    "\n",
    "We want to obtain an estimate for the mean value of an observable $A$:\n",
    "$$\\langle A \\rangle = \\sum_s A_s e^{-\\beta E_s}/\\sum_s e^{-\\beta E_s},$$\n",
    "where $E_s$ and $A_s$ are the values of the energy and the quantity $A$\n",
    "in the configuration $s$. The idea of using Monte Carlo consists in\n",
    "sampling a subset of configuration and approximating the average by the\n",
    "mean over the sample:\n",
    "$$\\langle A \\rangle \\simeq \\sum_s^{m} A_s e^{-\\beta E_s}/\\sum_s^{m}\n",
    "e^{-\\beta E_s},$$ where the sampling is over $m$ configurations. That is, rather than evaluating the energy for every possible microstate, we only want to consider those that are \"likely\" to be reached at the given temperature. \n",
    "\n",
    "A crude Monte Carlo procedure is to generate a configuration at random,\n",
    "calculate $E_s$ and $A_s$, and the contributions of this configuration\n",
    "to the sums. This is equivalent to the “hit and miss” Monte Carlo method\n",
    "for evaluating integrals. However, this would be very inefficient, because the configurations generated would likely be very\n",
    "improbable and contribute very little to the sum. Instead, we want to\n",
    "generate a sample of configurations that are <span>*important*</span>,\n",
    "<span>*i. e.*</span> have large contributions to the sums. This is equivalent to “importance sampling”. Hence, we need to\n",
    "generate the configurations according to a probability distribution. In\n",
    "this case, the most convenient is the Boltzmann\n",
    "probability itself $P_s$. Since we will average over the\n",
    "$m$ configurations generated with this probability, we must use the\n",
    "expression:\n",
    "$$\\langle A \\rangle \\simeq \\sum_s^{m} \\frac{A_s}{P_s} e^{-\\beta\n",
    "E_s}/\\sum_s^{m} \\frac{1}{P_s}e^{-\\beta E_s}\n",
    "= \\frac{1}{m}\\sum_s^{m}A_s$$\n",
    "\n",
    "The idea of the Monte Carlo algorithm is to attempt a random\n",
    "walk over the space of configurations. The walker “hops” from a\n",
    "configuration $i$ to another $j$ using the “transition probability”\n",
    "$$W=\\min{\\left(1,\\frac{P_j}{P_i}\\right)}.$$ Replacing by the\n",
    "corresponding expression, we obtain:\n",
    "$$W=\\min{\\left(1,e^{-\\beta(E_j-E_i)}\\right)}.$$\n",
    "\n",
    "Since we are only interested in the ratio $P_j/P_i$, it is not necessary\n",
    "to know the normalization constant $Z$. Although we have picked this\n",
    "expression for the transition probability $W$, is not the only choice.\n",
    "It can be shown that the only requirement is that $W$ satisfies the\n",
    "“detailed balance” condition:\n",
    "$$W(i \\rightarrow j)e^{-\\beta E_i} = W(j \\rightarrow i)e^{-\\beta E_j}.$$\n",
    "\n",
    "\n",
    "The pseudocode for a Monte Carlo simulation can be outlined as follows:\n",
    "\n",
    "1.  Establish an initial configuration.\n",
    "\n",
    "2.  Make a random trial change in the configuration. For example, choose\n",
    "    a spin at random and try to flip it. Or choose a particle at random\n",
    "    and attempt to displace it a random distance.\n",
    "\n",
    "3.  Compute the change in the energy of the system $\\Delta E$ due to the\n",
    "    trial change.\n",
    "\n",
    "4.  If $\\Delta E \\leq 0$, accept the new configuration and go to step 8.\n",
    "\n",
    "5.  If $\\Delta E$ is positive, compute the “transition probability”\n",
    "    $W=e^{-\\beta \\Delta E}$.\n",
    "\n",
    "6.  Generate a random number $r$ in the interval $[0,1]$.\n",
    "\n",
    "7.  If $r \\leq W$, accept the new configuration; otherwise retain the\n",
    "    previous configuration.\n",
    "\n",
    "8.  Repeat steps (2) to (7) to obtain a sufficient number of\n",
    "    configurations or “trials”.\n",
    "\n",
    "9.  Compute averages over configurations which are statistically\n",
    "    independent of each other.\n",
    "    \n",
    "### Important conditions for validity\n",
    "\n",
    "A Monte Carlo algorithm must satisfy detailed balance, but also **Ergodicity**. This means that the possible moves should guarantee that the system will explore the entire phase space. If there are regions of phase space that are not accessible via local moves, for instance, one should implement global moves or more complex update strategies.\n",
    "\n",
    "## HW\n",
    "\n",
    "Problem 1: Write a program that will simulate a 1D ising system.  That is, each spin interacts with its nearest neighbor, with a spin-spin coupling constant (for convenience, use 1).  Employ periodic boundary conditions, so that spin 1 and N are coupled. Using reduced units, calculate the specific heat at T=0.2$*$NT, for $1\\le NT \\lt \\ 25$. Study a system with 100 spins. To equilibrate the system, perform $10^6$ MC trials.  Then, for production, perform $10^7$ trials.  If there is a (pseudo) phase transition between an ordered and disordered state, then there should be a peak in the specific heat.  Is there a phase transition?  Is this consistent with expectations? Tip: It is probably easiest to calculate the specific heat by using the variance of the energies (think back to Phys 7305).\n",
    "\n",
    "Problem 2: Repeat problem 1 using a 2D ising system. Again using 100 spins, but in a square lattice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-treat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
